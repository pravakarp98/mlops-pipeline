---
data_split:
  test_size: 0.2
  random_state: 42

models:
  models:
  LogisticRegression:
    max_iter: 1000
    random_state: 42
  
  RandomForest:
    n_estimators: 100
    random_state: 42
    n_jobs: -1

  SVC:
    # We can add parameters here later for hyperparameter tuning
    # Example: C: 1.0, kernel: 'rbf'
    random_state: 42

  DecisionTree:
    random_state: 42

  GradientBoosting:
    random_state: 42
    n_estimators: 100

  AdaBoost:
    random_state: 42
    n_estimators: 50

  KNN:
    n_neighbors: 5
    n_jobs: -1

  GaussianNB: {}

tuning:
  n_iter: 20         # Number of combinations to try (start small, e.g., 20-50)
  cv: 3              # Cross-validation folds (3 is faster than 5)
  scoring: accuracy
  n_jobs: -1         # Use all CPU cores

  # Search space for Gradient Boosting
  GradientBoosting:
    param_grid:
      model__n_estimators: [100, 200, 300]
      model__learning_rate: [0.01, 0.05, 0.1, 0.2]
      model__max_depth: [3, 4, 5]
      model__min_samples_split: [2, 5, 10]
      model__subsample: [0.8, 0.9, 1.0]

  # Search space for Random Forest (Alternative)
  RandomForest:
    param_grid:
      model__n_estimators: [100, 200, 300]
      model__max_depth: [10, 20, 30, null]
      model__min_samples_split: [2, 5, 10]
      model__min_samples_leaf: [1, 2, 4]